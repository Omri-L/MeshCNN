<img src='docs/imgs/logo.jpg' align="center" width=700>
<br><br><br>

# QuadMeshCNN in PyTorch


QuadMeshCNN is an extension of MeshCNN method, which is a general-purpose deep neural network for 3D shapes, which can be used for tasks such as 3D shape classification. This framework includes convolution, pooling and unpooling layers which are applied directly on the mesh edges.


The code was adjusted to 3D quad meshes by [Omri Levi](https://www.linkedin.com/in/omri-levi-063167109/) as part of the requirements for the Degree of M.Sc in EE at TAU.
Original code from [MeshCNN](https://github.com/ranahanocka/MeshCNN.git) by [Rana Hanocka](https://www.cs.tau.ac.il/~hanocka/)

# Getting Started

### Installation
- Clone this repo:
```bash
git clone https://github.com/Omri-L/QuadMeshCNN
cd QuadMeshCNN
```
- Install dependencies: [PyTorch](https://pytorch.org/) version 1.2. <i> Optional </i>: [tensorboardX](https://github.com/lanpa/tensorboardX) for training plots.
  - Via new conda environment `conda env create -f environment.yml` (creates an environment called quadmeshcnn)
  
### 3D Shape Classification on QuadZoo5
<img src='docs/imgs/QuadZoo5.png' align="center" width=450px>

Download the dataset: [Google Drive](https://drive.google.com/file/d/1A1h_3teFS51H7hTw-Omphe8IQfDHEZth/view?usp=sharing).

And extract to QuadMeshCNN/datasets/QuadZoo5


Run training (if using conda env first activate env e.g. ```source activate quadmeshcnn```)
```
python train.py --dataroot datasets/QuadZoo5 --name QuadZoo5Train --ncf 64 128 256 256 --pool_res 1100 900 600 400 --norm group --resblocks 1 --num_aug 30 --scale_verts 0.1 --slide_verts 0.1 --rotate_edges 0.1 --batch_size 8 --ninput_edges 1954 --dataset_mode classification --niter_decay 700 --niter 350 --lr 0.0001
```

To view the training loss plots, in another terminal run ```tensorboard --logdir runs``` or ```tensorboard --logdir runs --bind_all``` (if you are not on your local machine).
Copy the URL generated by the command and paste on your browser.

Run test and export the intermediate pooled meshes:
```
python test.py --dataroot datasets/QuadZoo5 --name QuadZoo5Test --ncf 64 128 256 256 --pool_res 1100 900 600 400 --norm group --resblocks 1 --num_aug 30 --scale_verts 0.1 --slide_verts 0.1 --rotate_edges 0.1 --batch_size 1 --ninput_edges 1954 --dataset_mode classification
```
Make sure you have model weights in the checkpoints dir.

Visualize the network-learned edge collapses:
Add to the above test command the following parameter:
```
--export_folder FolderExamples
```

An example of collapses for a mesh:

<img src="/docs/imgs/collapses.png" width="450px"/>

# Citation
If you find this code useful, please consider citing our paper
```
@article{hanocka2019meshcnn,
  title={MeshCNN: A Network with an Edge},
  author={Hanocka, Rana and Hertz, Amir and Fish, Noa and Giryes, Raja and Fleishman, Shachar and Cohen-Or, Daniel},
  journal={ACM Transactions on Graphics (TOG)},
  volume={38},
  number={4},
  pages = {90:1--90:12},
  year={2019},
  publisher={ACM}
}
```
  
# Acknowledgments
Original code from [MeshCNN](https://github.com/ranahanocka/MeshCNN.git).

This code design was adopted from [pytorch-CycleGAN-and-pix2pix](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix).

Quad mesh illustration images are from: [human_link](https://3dmodelsz.blogspot.com/2020/03/3d-human-mesh.html), [penguin_link](https://3docean.net/item/penguin-base-mesh/9190779)

<img src='docs/imgs/penguin.png' align="left" width=160>
